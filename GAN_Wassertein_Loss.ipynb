{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75d4efbf-79b5-43cc-a81f-7cb72b80d4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71b4ab14-22e5-4a42-9b38-2415d363f215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport zipfile\\nimport os\\n\\nzip_path = \"./scrabblegan_dataset.zip\"  # Update with the actual filename\\nextract_path = \"./dataset\"\\n\\n# Extract if not already extracted\\nif not os.path.exists(extract_path):\\n    with zipfile.ZipFile(zip_path, \\'r\\') as zip_ref:\\n        zip_ref.extractall(extract_path)\\n\\nprint(\"✅ Dataset extracted.\")\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run once to extract dataset from zip file\n",
    "\"\"\"\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "zip_path = \"./scrabblegan_dataset.zip\"  # Update with the actual filename\n",
    "extract_path = \"./dataset\"\n",
    "\n",
    "# Extract if not already extracted\n",
    "if not os.path.exists(extract_path):\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_path)\n",
    "\n",
    "print(\"✅ Dataset extracted.\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c6bb37e-5a63-4279-8f1d-0865d2b95f6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport os\\n\\nfolder_path = \"C:\\\\Users\\\\jelly\\\\Desktop\\\\Sem-6\\\\GAN\\\\Project_Handwritten_Text_Generation\\\\dataset\\\\\"\\ndeleted_count = 0  # Counter for deleted files\\n\\nfor filename in os.listdir(folder_path):\\n    file_path = os.path.join(folder_path, filename)\\n    if os.path.getsize(file_path) == 0:  # Check if file is empty\\n        print(f\"❌ Deleting empty file: {filename}\")\\n        os.remove(file_path)\\n        deleted_count += 1  # Increment counter\\n\\nprint(f\"✅ All empty files deleted! Total files deleted: {deleted_count}\")\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Deleting all corrupt files, run once after dataset is unzipped\n",
    "\"\"\"\n",
    "import os\n",
    "\n",
    "folder_path = \"C:\\\\Users\\\\jelly\\\\Desktop\\\\Sem-6\\\\GAN\\\\Project_Handwritten_Text_Generation\\\\dataset\\\\\"\n",
    "deleted_count = 0  # Counter for deleted files\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    if os.path.getsize(file_path) == 0:  # Check if file is empty\n",
    "        print(f\"❌ Deleting empty file: {filename}\")\n",
    "        os.remove(file_path)\n",
    "        deleted_count += 1  # Increment counter\n",
    "\n",
    "print(f\"✅ All empty files deleted! Total files deleted: {deleted_count}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5ba3872-6820-4eb9-8a0b-362b8168013a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import glob\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class HandwritingDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        # Collect paired images (printed -> handwritten)\n",
    "        self.pairs = []\n",
    "        printed_images = glob.glob(os.path.join(root_dir, \"**\", \"*_printed.png\"), recursive=True)\n",
    "\n",
    "        for printed in printed_images:\n",
    "            handwritten = printed.replace(\"_printed.png\", \"_handwritten.png\")\n",
    "            if os.path.exists(handwritten):\n",
    "                self.pairs.append((printed, handwritten))\n",
    "\n",
    "        if len(self.pairs) == 0:\n",
    "            raise ValueError(\"❌ No paired images found! Check dataset structure.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        printed_path, handwritten_path = self.pairs[idx]\n",
    "\n",
    "        printed_img = Image.open(printed_path).convert(\"L\")\n",
    "        handwritten_img = Image.open(handwritten_path).convert(\"L\")\n",
    "\n",
    "        if self.transform:\n",
    "            printed_img = self.transform(printed_img)\n",
    "            handwritten_img = self.transform(handwritten_img)\n",
    "\n",
    "        return printed_img, handwritten_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bd64691-8483-4068-ba64-7d6dc166c32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 128)),  # Resize to consistent dimensions\n",
    "    transforms.ToTensor(),          \n",
    "    transforms.Normalize((0.5,), (0.5,))  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d45dd90-d19d-482f-b0bd-3584401ec724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset loaded with 44563 samples.\n"
     ]
    }
   ],
   "source": [
    "dataset = HandwritingDataset(root_dir=\"./dataset\", transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "print(f\"✅ Dataset loaded with {len(dataset)} samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a5af9f8-e81e-4b48-91a0-1ce2798b7961",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(channels, channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(channels, channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out += residual  # Skip connection\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.initial = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.res_blocks = nn.Sequential(*[ResidualBlock(64) for _ in range(8)])  # 8 residual layers\n",
    "\n",
    "        self.final = nn.Sequential(\n",
    "            nn.Conv2d(64, 1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.initial(x)\n",
    "        x = self.res_blocks(x)\n",
    "        x = self.final(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54b6e49e-4271-42be-879b-31ef100a500f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(512, 1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(4 * 16 * 1, 1)  # Adjust for input size 32x128\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65f73e37-3366-4fd7-8876-e1e5e3a57ed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# ===================== Generator =====================\\nclass Generator(nn.Module):\\n    def __init__(self):\\n        super(Generator, self).__init__()\\n\\n        layers = [\\n            nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1),\\n            nn.ReLU()\\n        ]\\n\\n        # 48 Additional Conv Layers\\n        for _ in range(8):\\n            layers.append(nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1))\\n            layers.append(nn.BatchNorm2d(64))\\n            layers.append(nn.ReLU())\\n\\n        layers.append(nn.Conv2d(64, 1, kernel_size=3, stride=1, padding=1))\\n        layers.append(nn.Tanh())  # Normalize output to [-1, 1]\\n\\n        self.model = nn.Sequential(*layers)\\n\\n    def forward(self, x):\\n        return self.model(x)\\n\\n# ===================== Discriminator =====================\\nclass Discriminator(nn.Module):\\n    def __init__(self):\\n        super(Discriminator, self).__init__()\\n\\n        layers = [\\n            nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1),\\n            nn.LeakyReLU(0.2)\\n        ]\\n\\n        # 48 Additional Conv Layers\\n        for _ in range(8):\\n            layers.append(nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1))\\n            layers.append(nn.BatchNorm2d(64))\\n            layers.append(nn.LeakyReLU(0.2))\\n\\n        layers.append(nn.Conv2d(64, 1, kernel_size=3, stride=1, padding=1))\\n        layers.append(nn.Flatten())\\n\\n        # Adjust Linear Layer for (64, 256) input shape\\n        layers.append(nn.Linear(32 * 128, 1))\\n\\n        self.model = nn.Sequential(*layers)\\n\\n    def forward(self, x):\\n        return self.model(x)\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# ===================== Generator =====================\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        layers = [\n",
    "            nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU()\n",
    "        ]\n",
    "\n",
    "        # 48 Additional Conv Layers\n",
    "        for _ in range(8):\n",
    "            layers.append(nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1))\n",
    "            layers.append(nn.BatchNorm2d(64))\n",
    "            layers.append(nn.ReLU())\n",
    "\n",
    "        layers.append(nn.Conv2d(64, 1, kernel_size=3, stride=1, padding=1))\n",
    "        layers.append(nn.Tanh())  # Normalize output to [-1, 1]\n",
    "\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# ===================== Discriminator =====================\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        layers = [\n",
    "            nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        ]\n",
    "\n",
    "        # 48 Additional Conv Layers\n",
    "        for _ in range(8):\n",
    "            layers.append(nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1))\n",
    "            layers.append(nn.BatchNorm2d(64))\n",
    "            layers.append(nn.LeakyReLU(0.2))\n",
    "\n",
    "        layers.append(nn.Conv2d(64, 1, kernel_size=3, stride=1, padding=1))\n",
    "        layers.append(nn.Flatten())\n",
    "\n",
    "        # Adjust Linear Layer for (64, 256) input shape\n",
    "        layers.append(nn.Linear(32 * 128, 1))\n",
    "\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce401602-8df2-423b-bc84-3c77228b0829",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"def gradient_penalty(D, real_samples, fake_samples, device=\"cuda\"):\n",
    "    alpha = torch.rand(real_samples.size(0), 1, 1, 1).to(device)\n",
    "    interpolated = (alpha * real_samples + (1 - alpha) * fake_samples).requires_grad_(True)\n",
    "\n",
    "    critic_interpolates = D(interpolated)\n",
    "    gradients = torch.autograd.grad(outputs=critic_interpolates, inputs=interpolated,\n",
    "                                    grad_outputs=torch.ones_like(critic_interpolates),\n",
    "                                    create_graph=True, retain_graph=True)[0]\n",
    "\n",
    "    gradients = gradients.view(gradients.size(0), -1)\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "    return gradient_penalty\n",
    "\"\"\"\n",
    "def gradient_penalty(D, real_samples, fake_samples, device=\"cuda\"):\n",
    "    alpha = torch.rand(real_samples.size(0), 1, 1, 1, device=device)\n",
    "    interpolated = (alpha * real_samples + (1 - alpha) * fake_samples).requires_grad_(True)\n",
    "\n",
    "    critic_interpolates = D(interpolated)\n",
    "    gradients = torch.autograd.grad(\n",
    "        outputs=critic_interpolates,\n",
    "        inputs=interpolated,\n",
    "        grad_outputs=torch.ones_like(critic_interpolates),\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "        only_inputs=True\n",
    "    )[0]\n",
    "\n",
    "    # Compute gradient norm\n",
    "    grad_norm = gradients.view(gradients.size(0), -1).norm(2, dim=1)\n",
    "    #print(f\"Mean Gradient Norm: {grad_norm.mean().item()}\")  # Debugging\n",
    "\n",
    "    return ((grad_norm - 1) ** 2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3be81af1-a902-441e-84a1-f85b4eb13d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "del generator, discriminator\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19224b3b-7588-40f4-adee-245a02f0012e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "generator = Generator().to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "#Consider using (0.0, 0.9) as betas for more stable training\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=0.0001, betas=(0.5, 0.9))\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0001, betas=(0.5, 0.9))\n",
    "\n",
    "# Consider using RMSprop optimizer as used with original WGAN\n",
    "\"\"\"\n",
    "optimizer_G = optim.RMSprop(generator.parameters(), lr=0.00005)\n",
    "optimizer_D = optim.RMSprop(discriminator.parameters(), lr=0.00005)\n",
    "\"\"\"\n",
    "\n",
    "#Consider lowering this value, as it might be reducing the impact of wassertein loss itself\n",
    "lambda_gp = 40  # Gradient penalty weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "464e4635-434e-4280-9a60-990679b81822",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jelly\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\torch\\autograd\\graph.py:768: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\cuda\\CublasHandlePool.cpp:135.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "Epoch 1/50: 100%|██████████| 2786/2786 [06:02<00:00,  7.68it/s, D Loss=-14.2580, G Loss=Skipping] \n",
      "Epoch 2/50: 100%|██████████| 2786/2786 [06:18<00:00,  7.35it/s, D Loss=-23.7586, G Loss=Skipping]  \n",
      "Epoch 3/50: 100%|██████████| 2786/2786 [07:06<00:00,  6.53it/s, D Loss=-9.1151, G Loss=Skipping]    \n",
      "Epoch 4/50: 100%|██████████| 2786/2786 [07:25<00:00,  6.25it/s, D Loss=1469.0934, G Loss=Skipping]    \n",
      "Epoch 5/50: 100%|██████████| 2786/2786 [07:29<00:00,  6.20it/s, D Loss=422.6858, G Loss=Skipping]     \n",
      "Epoch 6/50: 100%|██████████| 2786/2786 [06:41<00:00,  6.94it/s, D Loss=-3067.1558, G Loss=Skipping]   \n",
      "Epoch 7/50: 100%|██████████| 2786/2786 [06:24<00:00,  7.24it/s, D Loss=109.8958, G Loss=Skipping]      \n",
      "Epoch 8/50: 100%|██████████| 2786/2786 [06:07<00:00,  7.57it/s, D Loss=-7658.3101, G Loss=Skipping]  \n",
      "Epoch 9/50: 100%|██████████| 2786/2786 [06:13<00:00,  7.45it/s, D Loss=-14131.7764, G Loss=Skipping]   \n",
      "Epoch 10/50: 100%|██████████| 2786/2786 [06:13<00:00,  7.45it/s, D Loss=-15.2318, G Loss=Skipping]     \n",
      "Epoch 11/50: 100%|██████████| 2786/2786 [06:00<00:00,  7.74it/s, D Loss=-14.1753, G Loss=Skipping]   \n",
      "Epoch 12/50: 100%|██████████| 2786/2786 [06:06<00:00,  7.60it/s, D Loss=47.2052, G Loss=Skipping]      \n",
      "Epoch 13/50: 100%|██████████| 2786/2786 [06:06<00:00,  7.59it/s, D Loss=-63867.1719, G Loss=Skipping]  \n",
      "Epoch 14/50: 100%|██████████| 2786/2786 [06:08<00:00,  7.56it/s, D Loss=-168602.7344, G Loss=Skipping]  \n",
      "Epoch 15/50: 100%|██████████| 2786/2786 [06:07<00:00,  7.57it/s, D Loss=-337445.8125, G Loss=Skipping]   \n",
      "Epoch 16/50: 100%|██████████| 2786/2786 [06:12<00:00,  7.48it/s, D Loss=-552378.0625, G Loss=Skipping]   \n",
      "Epoch 17/50: 100%|██████████| 2786/2786 [05:50<00:00,  7.95it/s, D Loss=-994380.3750, G Loss=Skipping]    \n",
      "Epoch 18/50: 100%|██████████| 2786/2786 [06:18<00:00,  7.36it/s, D Loss=-1574793.1250, G Loss=Skipping]   \n",
      "Epoch 19/50: 100%|██████████| 2786/2786 [06:05<00:00,  7.62it/s, D Loss=-2035565.2500, G Loss=Skipping]    \n",
      "Epoch 20/50: 100%|██████████| 2786/2786 [06:06<00:00,  7.60it/s, D Loss=-3248644.5000, G Loss=Skipping]    \n",
      "Epoch 21/50: 100%|██████████| 2786/2786 [06:10<00:00,  7.53it/s, D Loss=3632375.0000, G Loss=Skipping]     \n",
      "Epoch 22/50: 100%|██████████| 2786/2786 [06:07<00:00,  7.58it/s, D Loss=2410.4763, G Loss=Skipping]        \n",
      "Epoch 23/50: 100%|██████████| 2786/2786 [06:05<00:00,  7.61it/s, D Loss=22.6547, G Loss=Skipping]      \n",
      "Epoch 24/50: 100%|██████████| 2786/2786 [06:09<00:00,  7.54it/s, D Loss=-9.3496, G Loss=Skipping]      \n",
      "Epoch 25/50: 100%|██████████| 2786/2786 [06:34<00:00,  7.06it/s, D Loss=-3.5329, G Loss=Skipping]      \n",
      "Epoch 26/50: 100%|██████████| 2786/2786 [05:57<00:00,  7.80it/s, D Loss=-10.4916, G Loss=Skipping]    \n",
      "Epoch 27/50: 100%|██████████| 2786/2786 [05:54<00:00,  7.85it/s, D Loss=-8.1282, G Loss=Skipping]     \n",
      "Epoch 28/50: 100%|██████████| 2786/2786 [05:51<00:00,  7.92it/s, D Loss=-10.0804, G Loss=Skipping]    \n",
      "Epoch 29/50: 100%|██████████| 2786/2786 [05:47<00:00,  8.01it/s, D Loss=-14.6344, G Loss=Skipping]    \n",
      "Epoch 30/50: 100%|██████████| 2786/2786 [05:45<00:00,  8.06it/s, D Loss=-14.6476, G Loss=Skipping]    \n",
      "Epoch 31/50: 100%|██████████| 2786/2786 [05:41<00:00,  8.15it/s, D Loss=-11.1799, G Loss=Skipping]    \n",
      "Epoch 32/50: 100%|██████████| 2786/2786 [05:46<00:00,  8.05it/s, D Loss=-18.0688, G Loss=Skipping]    \n",
      "Epoch 33/50: 100%|██████████| 2786/2786 [05:45<00:00,  8.06it/s, D Loss=-14.0137, G Loss=Skipping]    \n",
      "Epoch 34/50: 100%|██████████| 2786/2786 [05:47<00:00,  8.03it/s, D Loss=-10.7425, G Loss=Skipping]    \n",
      "Epoch 35/50: 100%|██████████| 2786/2786 [05:46<00:00,  8.03it/s, D Loss=-4.1024, G Loss=Skipping]     \n",
      "Epoch 36/50: 100%|██████████| 2786/2786 [05:46<00:00,  8.04it/s, D Loss=-12.7016, G Loss=Skipping]    \n",
      "Epoch 37/50: 100%|██████████| 2786/2786 [05:47<00:00,  8.01it/s, D Loss=-3.2588, G Loss=Skipping]     \n",
      "Epoch 38/50: 100%|██████████| 2786/2786 [05:46<00:00,  8.05it/s, D Loss=-12.3160, G Loss=Skipping]    \n",
      "Epoch 39/50: 100%|██████████| 2786/2786 [05:45<00:00,  8.06it/s, D Loss=-11.6608, G Loss=Skipping]    \n",
      "Epoch 40/50: 100%|██████████| 2786/2786 [05:43<00:00,  8.12it/s, D Loss=-8.5561, G Loss=Skipping]     \n",
      "Epoch 41/50: 100%|██████████| 2786/2786 [05:45<00:00,  8.07it/s, D Loss=-17.6067, G Loss=Skipping]    \n",
      "Epoch 42/50: 100%|██████████| 2786/2786 [05:46<00:00,  8.04it/s, D Loss=-17.4910, G Loss=Skipping]    \n",
      "Epoch 43/50: 100%|██████████| 2786/2786 [05:44<00:00,  8.08it/s, D Loss=-10.9408, G Loss=Skipping]    \n",
      "Epoch 44/50: 100%|██████████| 2786/2786 [05:45<00:00,  8.07it/s, D Loss=-5.8928, G Loss=Skipping]     \n",
      "Epoch 45/50: 100%|██████████| 2786/2786 [05:43<00:00,  8.11it/s, D Loss=-10.0127, G Loss=Skipping]    \n",
      "Epoch 46/50: 100%|██████████| 2786/2786 [05:41<00:00,  8.16it/s, D Loss=-8.8383, G Loss=Skipping]     \n",
      "Epoch 47/50: 100%|██████████| 2786/2786 [05:43<00:00,  8.11it/s, D Loss=-7.7196, G Loss=Skipping]     \n",
      "Epoch 48/50: 100%|██████████| 2786/2786 [06:15<00:00,  7.41it/s, D Loss=-7.1558, G Loss=Skipping]     \n",
      "Epoch 49/50: 100%|██████████| 2786/2786 [05:57<00:00,  7.79it/s, D Loss=-7.2308, G Loss=Skipping]     \n",
      "Epoch 50/50: 100%|██████████| 2786/2786 [05:46<00:00,  8.05it/s, D Loss=-15.3589, G Loss=Skipping]    \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "num_epochs = 50  # Number of training epochs\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    progress_bar = tqdm(dataloader, total=len(dataloader), desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "    for i, (printed_imgs, handwritten_imgs) in enumerate(progress_bar):\n",
    "        printed_imgs = printed_imgs.to(device, non_blocking=True)\n",
    "        handwritten_imgs = handwritten_imgs.to(device, non_blocking=True)\n",
    "\n",
    "        # ==================== Train Discriminator ====================\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        real_pred = discriminator(handwritten_imgs)\n",
    "        fake_imgs = generator(printed_imgs).detach()\n",
    "        fake_pred = discriminator(fake_imgs)\n",
    "\n",
    "        gp = gradient_penalty(discriminator, handwritten_imgs, fake_imgs, device)\n",
    "        d_loss = -torch.mean(real_pred) + torch.mean(fake_pred) + lambda_gp * gp\n",
    "\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # ==================== Train Generator ====================\n",
    "        g_loss_value = None\n",
    "        if i % 2 == 0:  # Train generator less frequently\n",
    "            optimizer_G.zero_grad()\n",
    "\n",
    "            fake_imgs = generator(printed_imgs)\n",
    "            fake_pred = discriminator(fake_imgs)\n",
    "\n",
    "            g_loss = -torch.mean(fake_pred)\n",
    "\n",
    "            g_loss.backward()\n",
    "            optimizer_G.step()\n",
    "\n",
    "            g_loss_value = g_loss.item()\n",
    "\n",
    "        # ==================== Update tqdm ====================\n",
    "        progress_bar.set_postfix({\n",
    "            \"D Loss\": f\"{d_loss.item():.4f}\",\n",
    "            \"G Loss\": f\"{g_loss_value:.4f}\" if g_loss_value else \"Skipping\"\n",
    "        })\n",
    "\n",
    "        # ==================== Free GPU Memory (Only After Both Updates) ====================\n",
    "        del real_pred, fake_imgs, fake_pred, gp, handwritten_imgs, d_loss\n",
    "        if g_loss_value is not None:\n",
    "            del g_loss\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b87e867e-6a08-4da9-9679-947df731aaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({'generator': generator.state_dict(), 'discriminator': discriminator.state_dict()}, \"model_checkpoint.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301dc2f9-ba63-44ba-8679-f9eeef12a30d",
   "metadata": {},
   "source": [
    "### Loading saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be6880aa-41dc-4cff-9fd4-8ba2f42cc580",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jelly\\AppData\\Local\\Temp\\ipykernel_3708\\1404931236.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\"model_checkpoint.pth\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Define your models first\n",
    "generator = Generator().to(device)  # Replace with your actual generator class\n",
    "discriminator = Discriminator().to(device)  # Replace with your actual discriminator class\n",
    "\n",
    "# Load the checkpoint\n",
    "checkpoint = torch.load(\"model_checkpoint.pth\")\n",
    "\n",
    "# Load the saved state dictionaries\n",
    "generator.load_state_dict(checkpoint['generator'])\n",
    "discriminator.load_state_dict(checkpoint['discriminator'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06369bb1-2979-4648-af2a-3deaa7a97356",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Load font (make sure the path to your font file is correct)\n",
    "font_path = \"arial.ttf\"  # Change to the actual font file path\n",
    "font_size = 40\n",
    "font = ImageFont.truetype(font_path, font_size)\n",
    "\n",
    "# Function to create a printed text image\n",
    "def text_to_input_image(text, img_size=(300, 100)):\n",
    "    img = Image.new(\"RGB\", img_size, \"white\")\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    draw.text((10, 30), text, font=font, fill=\"black\")\n",
    "    \n",
    "    # Resize to match the model input (32 x 128) and convert to grayscale\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=1),\n",
    "        transforms.Resize((32, 128)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5], std=[0.5])  # Normalize to match training distribution\n",
    "    ])\n",
    "\n",
    "    input_tensor = transform(img).unsqueeze(0)  # Add batch dimension\n",
    "    return input_tensor.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Move to GPU if available\n",
    "\n",
    "# Function to generate handwritten text image\n",
    "def generate_handwritten_image(text):\n",
    "    input_image_tensor = text_to_input_image(text)\n",
    "\n",
    "    # Generate handwritten image\n",
    "    with torch.no_grad():\n",
    "        handwritten_tensor = generator(input_image_tensor)  # Pass through the trained generator\n",
    "\n",
    "    # Convert output tensor to image\n",
    "    handwritten_tensor = handwritten_tensor.squeeze(0).cpu()  # Remove batch dimension and move to CPU\n",
    "    handwritten_tensor = (handwritten_tensor * 0.5) + 0.5  # Denormalize from [-1,1] to [0,1]\n",
    "\n",
    "    # Convert tensor to PIL image\n",
    "    handwritten_image = transforms.ToPILImage()(handwritten_tensor)\n",
    "\n",
    "    return handwritten_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "631bcdf1-fa38-4eaf-9b8e-32c6ac09a82c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for 'Random': \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for 'The': \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for 'Keys': \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example usage\n",
    "text = [\"Random\", \"The\", \"Keys\"]\n",
    "\n",
    "for text in text:\n",
    "    handwritten_image = generate_handwritten_image(text)\n",
    "    print(f\"Image for '{text}': \")\n",
    "    # Show image\n",
    "    plt.imshow(handwritten_image, cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
